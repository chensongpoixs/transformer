{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34bceb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "#import config\n",
    "import math\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# DEVICE = config.device\n",
    "device =   \"cuda\" if torch.cuda.is_available() else \"cpu\"; # 检查是否有可用的GPU,否则使用CPU\n",
    "print(\"Using {} device\".format(device)); # 打印使用的设备类型\n",
    "\"\"\"\n",
    "Transformer模型中前馈神经网络的实现。\n",
    "\"\"\"\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        位置前馈神经网络初始化函数\n",
    "        参数:\n",
    "            d_model: 模型的输入维度\n",
    "            d_ff: 前馈神经网络中间层的维度\n",
    "            dropout: dropout概率，默认为0.1\n",
    "        \"\"\"\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        # Linear层，将输入维度从d_model映射到d_ff  \n",
    "        self.w_1 = nn.Linear(d_model, d_ff)  # 第一个线性层，将维度从d_model扩展到d_ff\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)  # 第二个线性层，将维度从d_ff压缩回d_model\n",
    "        self.dropout = nn.Dropout(dropout)    # dropout层，用于防止过拟合\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))  # 先通过第一个线性层，然后应用ReLU激活函数，再经过dropout，最后通过第二个线性层返回结果\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09442bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "为每个输入位置添加一个唯一的位置编码\n",
    "这个编码会被添加到词向量中，使模型能够理解位置信息\n",
    "参考论文《Attention is All You Need》中的公式:\n",
    "# 偶数维度使用sin函数，奇数维度使用cos函数\n",
    "PE(pos, 2i)   = sin(pos / 10000^(2i/d_model))\n",
    "PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "其中 pos 是位置，i 是维度索引，d_model 是词向量的维度\n",
    "\n",
    "\"\"\"\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # 初始化一个size为 max_len(设定的最大长度)×embedding维度 的全零矩阵\n",
    "        # 来存放所有小于这个长度位置对应的positional embedding\n",
    "        pe = torch.zeros(max_len, d_model, device=device)\n",
    "        print(\"pe shape:\", pe.shape)  # pe shape: torch.Size([5000, 512])\n",
    "        print(\"pe:\", pe);\n",
    "        # 生成一个位置下标的tensor矩阵(每一行都是一个位置下标)\n",
    "        position = torch.arange(0., max_len, device=device).unsqueeze(1)\n",
    "        print(\"PositionalEncoding: d_model={}, max_len={}\".format(d_model, max_len));\n",
    "        print(\"position shape:\", position.shape)  # position shape: torch.Size([5000, 1])\n",
    "        # 这里幂运算太多，我们使用exp和log来转换实现公式中pos下面要除以的分母（由于是分母，要注意带负号）\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2, device=device) * -(math.log(10000.0) / d_model))\n",
    "\n",
    "        # 根据公式，计算各个位置在各embedding维度上的位置纹理值，存放到pe矩阵中\n",
    "        # 偶数维度使用sin函数，奇数维度使用cos函数  \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # 加1个维度，使得pe维度变为：1×max_len×embedding维度\n",
    "        # (方便后续与一个batch的句子所有词的embedding批量相加)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # 将pe矩阵以持久的buffer状态存下(不会作为要训练的参数)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 将一个batch的句子所有词的embedding与已构建好的positional embeding相加\n",
    "        # (这里按照该批次数据的最大句子长度来取对应需要的那些positional embedding值)\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24318923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe shape: torch.Size([5000, 512])\n",
      "pe: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "PositionalEncoding: d_model=512, max_len=5000\n",
      "position shape: torch.Size([5000, 1])\n",
      "pe after even: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 8.4147e-01,  0.0000e+00,  8.2186e-01,  ...,  0.0000e+00,\n",
      "          1.0366e-04,  0.0000e+00],\n",
      "        [ 9.0930e-01,  0.0000e+00,  9.3641e-01,  ...,  0.0000e+00,\n",
      "          2.0733e-04,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 9.5625e-01,  0.0000e+00,  9.3594e-01,  ...,  0.0000e+00,\n",
      "          4.9515e-01,  0.0000e+00],\n",
      "        [ 2.7050e-01,  0.0000e+00,  8.2251e-01,  ...,  0.0000e+00,\n",
      "          4.9524e-01,  0.0000e+00],\n",
      "        [-6.6395e-01,  0.0000e+00,  9.7326e-04,  ...,  0.0000e+00,\n",
      "          4.9533e-01,  0.0000e+00]], device='cuda:0')\n",
      "pe after odd: tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
      "          1.0366e-04,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
      "          2.0733e-04,  1.0000e+00],\n",
      "        ...,\n",
      "        [ 9.5625e-01, -2.9254e-01,  9.3594e-01,  ...,  8.5926e-01,\n",
      "          4.9515e-01,  8.6881e-01],\n",
      "        [ 2.7050e-01, -9.6272e-01,  8.2251e-01,  ...,  8.5920e-01,\n",
      "          4.9524e-01,  8.6876e-01],\n",
      "        [-6.6395e-01, -7.4778e-01,  9.7326e-04,  ...,  8.5915e-01,\n",
      "          4.9533e-01,  8.6871e-01]], device='cuda:0')\n",
      " --- IGNORE ---\n",
      "torch.Size([1, 5000, 512])\n"
     ]
    }
   ],
   "source": [
    "# 实例化FeedForward对象\n",
    "d_model=512;\n",
    "\n",
    "d_ff=2048; \n",
    "\n",
    "h=8;\n",
    "\n",
    "dropout=0.1;\n",
    "\n",
    "#ff = PositionwiseFeedForward(d_model, d_ff, dropout).to(device);\n",
    "\n",
    "\n",
    "# 实例化PositionalEncoding对象\n",
    "position = PositionalEncoding(d_model, dropout).to(device);\n",
    "\n",
    "\n",
    "# 实例化Transformer模型对象\n",
    "\n",
    "print(\"\"\" --- IGNORE ---\"\"\");\n",
    "print(position.pe.shape);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
